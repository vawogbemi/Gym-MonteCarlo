{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\victor a\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('GuessingGame-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(1,) Discrete(4)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space, env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "action = np.array([10000])\n",
    "env.step(action)\n",
    "print(env.observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_episode(env, Q, epsilon):\n",
    "    state = env.reset()\n",
    "    episode = []\n",
    "    s = -1000\n",
    "    e = 1000 \n",
    "    while True:\n",
    "        m = (s+e)/2\n",
    "        #Actions are to go low, high, or reset/restart\n",
    "        l = (s + m)/2\n",
    "        h = (e + m)/2\n",
    "        r = 0\n",
    "        actions = [l, h, r]\n",
    "        action = np.array([np.random.choice(actions, p = get_prob(Q[state], epsilon))])\n",
    "        state, reward, done, info = env.step(action)\n",
    "        if action == l:\n",
    "            e = m\n",
    "            categorical_action = 0\n",
    "        elif action == h:\n",
    "            s = m\n",
    "            categorical_action = 1\n",
    "        elif action == r:\n",
    "            s,e = -1000, 1000\n",
    "            categorical_action = 2\n",
    "        episode.append((state, categorical_action, reward))\n",
    "        if done:\n",
    "            break\n",
    "    return episode\n",
    "        \n",
    "def get_prob(Q_s, epsilon):\n",
    "    probs = np.zeros(3) + (epsilon/3)\n",
    "    best = np.argmax(Q_s)\n",
    "    probs[best] = 1 - epsilon + (epsilon/3)\n",
    "    return probs\n",
    "\n",
    "def update_Q(env, Q, episode, alpha, gamma):\n",
    "    states, actions, rewards = zip(*episode)\n",
    "    discounts = np.array([gamma**i for i in range(len(rewards)+1)])\n",
    "\n",
    "    for i, state in enumerate(states):\n",
    "        Q_prime = Q[state][actions[i]]\n",
    "        Q[state][actions[i]] = Q_prime + alpha*(sum(rewards[i:]*discounts[:-(i+1)]) - Q_prime)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GGMC(env, num_episodes = 600, alpha = 0.2, gamma = 0.99999999, epsilon_start= 1.0, epsilon_decay = 0.9999, epsilon_min = 0.2):\n",
    "    nA = 3\n",
    "    Q = defaultdict(lambda: np.zeros(3))\n",
    "    epsilon = epsilon_start\n",
    "    for i_episode in range(1, num_episodes + 1):\n",
    "        if i_episode % 10 == 0:\n",
    "            print(\"\\rEpisode {}/{}.\".format(i_episode, num_episodes), end=\"\")\n",
    "        epsilon = max(epsilon*epsilon_decay, epsilon_min)\n",
    "        episode = generate_episode(env, Q, epsilon)\n",
    "        Q = update_Q(env, Q, episode, alpha, gamma)\n",
    "    print()\n",
    "    print('Results')\n",
    "    print('Action 0: Low, Action 1: High, Action 2: Reset')\n",
    "    print()\n",
    "    print('State 0')\n",
    "    print(Q[0])\n",
    "    print('Ordered Values:',np.argsort(Q[0]))\n",
    "    print('Largest Value:',np.argmax(Q[0]))\n",
    "    print()\n",
    "    print('State 1')\n",
    "    print(Q[1])\n",
    "    print('Ordered Values:',np.argsort(Q[1]))\n",
    "    print('Largest Value:',np.argmax(Q[1]))\n",
    "    print()\n",
    "    print('State 3')\n",
    "    print(Q[3])\n",
    "    print('Ordered Values:',np.argsort(Q[3]))\n",
    "    print('Largest Value:',np.argmax(Q[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 600/600.\n",
      "Results\n",
      "\n",
      "State 0\n",
      "[0. 0. 0.]\n",
      "Ordered Values: [0 1 2]\n",
      "Largest Value: 0\n",
      "\n",
      "State 1\n",
      "[1.69919043e-20 4.92394656e-13 6.47950761e-20]\n",
      "Ordered Values: [0 2 1]\n",
      "Largest Value: 1\n",
      "\n",
      "State 3\n",
      "[1.09636737e-19 2.33597139e-22 6.53485872e-19]\n",
      "Ordered Values: [1 0 2]\n",
      "Largest Value: 2\n"
     ]
    }
   ],
   "source": [
    "GGMC(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes and Ending Remarks\n",
    "I think I made a mistake to create the third action of reseting, because sometimes it has the largest q value. I tried changing the parameters a bunch but somehow the third one was still sometimes the highest value action. I even tried giving a negative reward upon choosing the third action and that somehow always made the third action the highest value. Anyways I should of just been more nature and made it only lower or higher and wont care if the episodes don't finish and give certain actions 0 value. I'm just glad that it seems to consistently choose the best policy if you disregrad the reset action. This did make me interested in doing evolutionary algorithms though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
